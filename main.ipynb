{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "torchtext.disable_torchtext_deprecation_warning()\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import warnings\n",
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from torchtext.vocab import GloVe\n",
    "from collections import Counter\n",
    "from torchtext.vocab import GloVe\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(Attention, self).__init__()\n",
    "        self.attention = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, lstm_output):\n",
    "        attn_weights = F.softmax(self.attention(lstm_output), dim=1)\n",
    "        context = torch.sum(attn_weights * lstm_output, dim=1)\n",
    "        return context, attn_weights\n",
    "\n",
    "class SentimentClassifierLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_layers, output_dim, dropout):\n",
    "        super(SentimentClassifierLSTM, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.attention = Attention(hidden_dim)\n",
    "        self.fc1 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        lstm_output, (hidden, _) = self.lstm(embedded)\n",
    "        context, attn_weights = self.attention(lstm_output)\n",
    "        hidden = self.dropout(context)\n",
    "        hidden = torch.relu(self.fc1(hidden))\n",
    "        output = self.fc2(hidden)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.replace('\\n', ' ')\n",
    "    text = re.sub(r'[^A-Za-z0-9\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "\n",
    "def tokenize_text(text):\n",
    "    tokens = text.split()\n",
    "    return [glove.stoi[token] for token in tokens if token in glove.stoi]\n",
    "\n",
    "\n",
    "def predict_sentiment_LSTM(text):\n",
    "    sentiment_mapping = {0: 'negative', 1: 'neutral', 2: 'positive'}\n",
    "    text = clean_text(text)\n",
    "    tokens = tokenize_text(text)\n",
    "    padded_tokens = tokens[:max_len] + [0] * (max_len - len(tokens))\n",
    "    input_tensor = torch.tensor(padded_tokens, dtype=torch.long).unsqueeze(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model_LSTM(input_tensor)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "    return sentiment_mapping[predicted.item()]\n",
    "\n",
    "\n",
    "def predict_sentiment_XLMRoBERTa(text):\n",
    "    sentiment_mapping = {0: 'negative', 1: 'neutral', 2: 'positive'}\n",
    "\n",
    "    inputs = tokenizer_xlm_roberta(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "    outputs = model_xlm_roberta(**inputs)\n",
    "    predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "    sentiment = torch.argmax(predictions, dim=1).item()\n",
    "    sentiment_label = sentiment_mapping[sentiment]\n",
    "\n",
    "    return sentiment_label\n",
    "\n",
    "\n",
    "def predict_sentiment_BERT(text):\n",
    "    sentiment_lower = {0: 0, 1: 0, 2: 1, 3: 2, 4: 2}\n",
    "\n",
    "    sentiment_mapping = {0: 'negative', 1: 'neutral', 2: 'positive'}\n",
    "\n",
    "    inputs = tokenizer_BERT(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "    outputs = model_BERT(**inputs)\n",
    "    predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "    sentiment = torch.argmax(predictions, dim=1).item()\n",
    "    sentiment_label = sentiment_mapping[sentiment_lower[sentiment]]\n",
    "\n",
    "    return sentiment_label\n",
    "\n",
    "\n",
    "def get_majority_label(predictions):\n",
    "    counter = Counter(predictions)\n",
    "    majority_label = counter.most_common(1)[0][0]\n",
    "    return majority_label\n",
    "\n",
    "\n",
    "def predict_sentiment_ensemble(text):\n",
    "    prediction_LSTM = predict_sentiment_LSTM(text)\n",
    "    prediction_XLMRoBERTa1 = predict_sentiment_XLMRoBERTa(text)\n",
    "    prediction_XLMRoBERTa2 = predict_sentiment_XLMRoBERTa(text)\n",
    "    prediction_BERT = predict_sentiment_BERT(text)\n",
    "\n",
    "    return get_majority_label((prediction_LSTM, prediction_XLMRoBERTa1, prediction_XLMRoBERTa2, prediction_BERT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"D:\\\\BSES - Data Analyst\\\\Sentiment Analysis\"\n",
    "\n",
    "processed_filepath = os.path.join(base_dir, \"newData\", \"New Processed Data.xlsx\")\n",
    "universal_filepath = os.path.join(base_dir, \"newData\", \"Universal.xlsx\")\n",
    "custom_embed_dir = os.path.join(base_dir, \"Embedding\")\n",
    "LSTM_path = os.path.join(base_dir, \"Models\", \"LSTM.pt\")\n",
    "custom_cache_dir = os.path.join(base_dir, \"Models\")\n",
    "to_process_path = os.path.join(base_dir, \"newData\", \"To Process\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model 1: LSTM + Attention Model\n",
      "Model 1 Loaded\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model 1: LSTM + Attention\n",
    "print(\"Loading Model 1: LSTM + Attention Model\")\n",
    "max_len = 500\n",
    "embed_dim = 300\n",
    "batch_size = 64\n",
    "hidden_dim = 100\n",
    "output_dim = 3\n",
    "dropout_rate = 0.2\n",
    "num_layers = 2\n",
    "glove = GloVe(name='6B', dim=embed_dim, cache=custom_embed_dir)\n",
    "vocab_size = len(glove.stoi)\n",
    "\n",
    "model_LSTM = SentimentClassifierLSTM(vocab_size, embed_dim, hidden_dim, num_layers, output_dim, dropout_rate)\n",
    "model_LSTM.load_state_dict(torch.load(LSTM_path))\n",
    "model_LSTM.eval()\n",
    "print(\"Model 1 Loaded\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model 2: XLM-RoBERTa Model\n",
      "Model 2 Loaded\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# XLM-RoBERTa Model\n",
    "print(\"Loading Model 2: XLM-RoBERTa Model\")\n",
    "model_name_RoBERTa = 'cardiffnlp/twitter-xlm-roberta-base-sentiment'\n",
    "os.makedirs(custom_cache_dir, exist_ok=True)\n",
    "tokenizer_xlm_roberta = AutoTokenizer.from_pretrained(model_name_RoBERTa, cache_dir=custom_cache_dir)\n",
    "model_xlm_roberta = AutoModelForSequenceClassification.from_pretrained(model_name_RoBERTa, cache_dir=custom_cache_dir)\n",
    "print(\"Model 2 Loaded\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model 3: BERT Model\n",
      "Model 3 Loaded\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# BERT Model\n",
    "print(\"Loading Model 3: BERT Model\")\n",
    "model_name_BERT = 'nlptown/bert-base-multilingual-uncased-sentiment'\n",
    "os.makedirs(custom_cache_dir, exist_ok=True)\n",
    "tokenizer_BERT = BertTokenizer.from_pretrained(model_name_BERT, cache_dir=custom_cache_dir)\n",
    "model_BERT = BertForSequenceClassification.from_pretrained(model_name_BERT, cache_dir=custom_cache_dir)\n",
    "print(\"Model 3 Loaded\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last Data in Universal: 2020-07-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "universal = pd.read_excel(universal_filepath, engine='openpyxl')\n",
    "last_date_universal = universal['Date'].max()\n",
    "print(f\"Last Data in Universal: {last_date_universal}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Excel file from path: D:\\BSES - Data Analyst\\Sentiment Analysis\\newData\\To Process\n",
      "Filename : Sentiment_Analysis_Date.xlsx\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0     lets see..as you guys even dont know my exact ...\n",
       "1     why power cut at this time . please help .. wh...\n",
       "2     it took me entire day to gather the informatio...\n",
       "3                                          no light????\n",
       "4     ca101347619\\n40Â° temperature and no power in ...\n",
       "5     when will you get back? problem is still persi...\n",
       "6     no electricity from past 1 hour in laxmi nagar...\n",
       "7     first 200 units rate is rs 3\\nbut 167units men...\n",
       "8     no electric power for almost 1hr in entire are...\n",
       "9     i am not able to do self meter reading for jul...\n",
       "10    no power in lalita park, #laxminagar kindly lo...\n",
       "11                                     voltage function\n",
       "12    at 2.oo am power supply cutt-off in haveli his...\n",
       "13    sir mera area me daily light ja rhi hai itni g...\n",
       "14    details already mentioned \\nnow complaint is f...\n",
       "Name: Customer_Text, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_process_file_name = os.listdir(to_process_path)\n",
    "to_process_file_path = os.path.join(to_process_path, to_process_file_name[0])\n",
    "print(f\"Reading Excel file from path: {to_process_path}\")\n",
    "print(f\"Filename : {to_process_file_name[0]}\")\n",
    "df = pd.read_excel(to_process_file_path, engine='openpyxl')\n",
    "if last_date_universal is np.nan:\n",
    "    data = df[\"Customer_Text\"].copy()\n",
    "else:\n",
    "    filtered_data = df[df['Date'] > last_date_universal].reset_index(drop=True)\n",
    "    data = filtered_data[\"Customer_Text\"].copy()\n",
    "\n",
    "data = data.astype(str)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Sentiments: 100%|██████████| 15/15 [00:03<00:00,  4.22it/s]\n"
     ]
    }
   ],
   "source": [
    "sentiment = []\n",
    "for text in tqdm(data, desc=\"Processing Sentiments\"):\n",
    "    text = text.replace('\\n', ' ').strip()\n",
    "    sentiment.append(predict_sentiment_ensemble(text))\n",
    "\n",
    "filtered_data[\"Sentiment\"] = sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "universal = pd.read_excel(universal_filepath, engine='openpyxl')\n",
    "new_universal = pd.concat([universal, filtered_data], ignore_index=True)\n",
    "new_universal.to_excel(universal_filepath, index=False)\n",
    "filtered_data.to_excel(processed_filepath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
